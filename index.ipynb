{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;\">CREATING A BOOK RECOMMENDATION SYSTEM</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">BUSINESS UNDERSTANDING  </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Project Overview  </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation systems are powerful tools that use machine learning algorithms to provide suggestions that are useful to users based on behaviour or habit patterns or user data. \n",
    "A Book Recommendation System is a machine learning-based solution designed to suggest books to users based on their preferences and behavior. Recommendation systems enhance user engagement, drive sales, and improve customer satisfaction by providing personalized suggestions. This project aims to utlize advance machine learning tools to develop a book recommendation system that is tailored to meet personalized customers needs and preferences therefore helping customers with the challenge of locating or choosing which books to read considering the large electronic book presence. The data used is from Kaggle  [Kaggle](https://www.kaggle.com/datasets/somnambwl/bookcrossing-dataset/data)\n",
    "\n",
    "There are two primary approaches to recommendation systems:\n",
    "\n",
    "1. Collaborative Filtering – Uses user behavior and preferences to make recommendations.\n",
    "\n",
    "2. Content-Based Filtering – Suggests books based on the features and attributes of previously liked books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Business Problem</h3>\n",
    "\n",
    "As earlier mentioned, with the rise of online and e-commerce services, customers face challenges in finding books that match their preferences. The goal is to develop a Book Recommendation System that offers personalized book suggestions, improving user experience and engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Project Objectives</h3>\n",
    "\n",
    "Develop a recommendation system that provides tailored book suggestions.\n",
    "\n",
    "Increase book sales by recommending books users are most likely to purchase.\n",
    "\n",
    "Enhance customer retention by offering relevant recommendations.\n",
    "\n",
    "Improve user engagement by making book discovery easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Key Analysis Questions:</h3>\n",
    "\n",
    "Which authors consistently receive high ratings?\n",
    "\n",
    "Does the year of publication influence book ratings?\n",
    "\n",
    "How accurate are the collaborative filtering recommendations?\n",
    "\n",
    "How does class imbalance in ratings affect recommendation performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Key Analysis Questions:</h3>\n",
    "\n",
    "Which authors consistently receive high ratings?\n",
    "\n",
    "Does the year of publication influence book ratings?\n",
    "\n",
    "How accurate are the collaborative filtering recommendations?\n",
    "\n",
    "How does class imbalance in ratings affect recommendation performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Data Source</h3>\n",
    "\n",
    "The dataset is obtained from Kaggle and consists of three files:\n",
    "\n",
    "Books.csv – Includes details such as ISBN, title, author, year, and publisher.\n",
    "\n",
    "Ratings.csv – Contains user ratings (0 to 10) linked to books via ISBN and user ID.\n",
    "\n",
    "Users.csv – Provides user demographics, including age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Data Source</h3>\n",
    "\n",
    "The dataset is obtained from Kaggle and consists of three files:\n",
    "\n",
    "Books.csv – Includes details such as ISBN, title, author, year, and publisher.\n",
    "\n",
    "Ratings.csv – Contains user ratings (0 to 10) linked to books via ISBN and user ID.\n",
    "\n",
    "Users.csv – Provides user demographics, including age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Stakeholders</h3>\n",
    "\n",
    "Customers – Expect personalized and accurate book recommendations.\n",
    "\n",
    "Marketing Team – Uses insights for targeted promotions and advertising.\n",
    "\n",
    "Data Scientists – Focus on optimizing the accuracy and scalability of the model.\n",
    "\n",
    "Book Authors – Gain insights into audience preferences and book popularity.\n",
    "\n",
    "Executives (CEO) – Assess the business impact of the recommendation system on revenue and customer retention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Methodology</h3>\n",
    "\n",
    "The project follows the CRISP-DM framework:\n",
    "\n",
    "Business Understanding – Define project goals and objectives.\n",
    "\n",
    "Data Understanding – Explore and assess data quality.\n",
    "\n",
    "Data Preparation – Clean and preprocess data.\n",
    "\n",
    "Modeling – Implement recommendation models.\n",
    "\n",
    "Evaluation – Assess model performance using relevant metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Data Understanding</h3>\n",
    "\n",
    "A thorough exploration of the dataset ensures high-quality inputs for model training.\n",
    "\n",
    "<h4 style=\"text-align:left;\">A. Dataset Overview</h4>\n",
    "\n",
    "Books Dataset – Provides ISBN, title, author, publisher, and publication year.\n",
    "\n",
    "Users Dataset – Contains user demographics, including age.\n",
    "\n",
    "Ratings Dataset – Includes user ratings for books (0-10 scale).\n",
    "\n",
    "<h4 style=\"text-align:left;\">B. Data Merging</h4>\n",
    "Merged Ratings.csv with Users.csv using User-ID.\n",
    "\n",
    "Further merged with Books.csv using ISBN to form a comprehensive dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align:left;\">C. Key Insights</h4>\n",
    "\n",
    "Outliers – Unreasonable age values need capping or removal.\n",
    "\n",
    "Missing Values –\n",
    "\n",
    "Age column has ~27% missing values; will be imputed using the median.\n",
    "\n",
    "Book-Author and Publisher have negligible missing values; will be dropped.\n",
    "\n",
    "Image URLs will be dropped as they are irrelevant to analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align:left;\">D. Data Analysis</h4>\n",
    "\n",
    "i) Univariate Analysis\n",
    "\n",
    "Book Ratings – Understand rating distribution and trends.\n",
    "\n",
    "User Ages – Identify major reading demographics.\n",
    "\n",
    "ii) Bivariate Analysis\n",
    "\n",
    "Age vs. Ratings – Understand rating preferences across age groups.\n",
    "\n",
    "Authors vs. Ratings – Identify consistently high-rated authors.\n",
    "\n",
    "Publisher vs. Ratings – Analyze publisher influence on book ratings.\n",
    "\n",
    "Publication Year vs. Ratings – Determine if newer books receive better ratings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Modeling</h3>\n",
    "\n",
    "We will develop and evaluate two types of recommendation models:\n",
    "\n",
    "1. Collaborative Filtering\n",
    "\n",
    "User-User Filtering – Recommends books based on user similarity.\n",
    "\n",
    "Item-Item Filtering – Suggests books similar to previously liked books.\n",
    "\n",
    "Techniques Used: SVD, Cosine Similarity.\n",
    "\n",
    "Challenge:\n",
    "\n",
    "Struggles with new users or books lacking sufficient interaction history (cold start problem).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Modeling Evaluation</h3>\n",
    "\n",
    "For evaluation, we use:\n",
    "\n",
    "Precision – Measures how many recommended books are relevant.\n",
    "\n",
    "Recall – Ensures a diverse and comprehensive recommendation list.\n",
    "\n",
    "F1-Score – Balances precision and recall.\n",
    "\n",
    "RMSE & MAE – Measures prediction accuracy.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Expected Results</h3>\n",
    "\n",
    "The primary focus is on precision, ensuring highly relevant recommendations that improve user satisfaction. The goal is to achieve a precision score of at least 75%, ensuring accurate and personalized book suggestions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\"> DATA PREPARATION </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section of the project, data is prepared for analysis by loading our data for inspection, visualizing it , cleaning it and performing feature engineering to better improve the dataset for analysis. All important libraries releveant to our project are also imported at this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Started by importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 438648, saw 3\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-3f858f97592a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Load 'ratings.csv' dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mRatings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Ratings.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mRatings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1196\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2153\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2154\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2155\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2156\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2157\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 438648, saw 3\n"
     ]
    }
   ],
   "source": [
    "#Load 'ratings.csv' dataset\n",
    "Ratings = pd.read_csv('Ratings.csv',low_memory=False)\n",
    "Ratings.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
